{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from PointNet import PointNet\n",
    "from PointCNN import PointCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to functions.py if you want to merge multiple datasets\n",
    "\n",
    "dataset1 = \"./combined_asl_alphabet/Train_Alphabet\"\n",
    "# dataset2 = \"./asl_dataset\"\n",
    "# dataset3 = \"./extras\"\n",
    "destination_path1 = \"./landmarks_1\"\n",
    "# destination_path2 = \"./landmarks_2\"\n",
    "# destination_path3 = \"./landmarks_3\"\n",
    "\n",
    "# CREATING DATASET DO NOT UNCOMMENT. \n",
    "# create_dataset(dataset1,destination_path1, transform)\n",
    "# create_dataset(dataset2,destination_path2, transform)\n",
    "# create_dataset(dataset3,destination_path3, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_folders(destination_path2, destination_path1)\n",
    "# merge_folders(destination_path3, destination_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = load_dataset(destination_path1)\n",
    "\n",
    "training, validation = random_split(items, [0.9, 0.1])\n",
    "training_input_tensor = torch.Tensor([x[0] for x in training])\n",
    "training_output_tensor = torch.LongTensor([int(x[1]) for x in training],device=device).long()\n",
    "validation_input_tensor = torch.Tensor([x[0] for x in validation])\n",
    "validation_output_tensor = torch.Tensor([int(x[1]) for x in validation], device=device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training: \", training_input_tensor.shape, training_output_tensor.shape)\n",
    "print(\"Validation: \", validation_input_tensor.shape, validation_output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "print(len(char2int))\n",
    "tensor_train_dataset = TensorDataset(training_input_tensor,training_output_tensor) \n",
    "train_dataloader = DataLoader(tensor_train_dataset, batch_size = batch_size, shuffle = True)\n",
    "tensor_val_dataset = TensorDataset(validation_input_tensor,validation_output_tensor)\n",
    "val_dataloader = DataLoader(tensor_val_dataset, batch_size = batch_size, shuffle = True)\n",
    "model1 = PointNet(len(char2int)).to(device)\n",
    "model2 = PointCNN(len(char2int)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_all1, acc_train_all1, loss_val_all1, acc_val_all1 = train_model(model1,epochs,train_dataloader,val_dataloader,\"PointNet-LR0.0001\",learn_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_all2, acc_train_all2, loss_val_all2, acc_val_all2 = train_model(model1,epochs,train_dataloader,val_dataloader,\"PointNet-LR0.00001\",learn_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_all3, acc_train_all3, loss_val_all3, acc_val_all3 = train_model(model2,epochs,train_dataloader,val_dataloader,\"PointCNN-LR0.001\",learn_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_all4, acc_train_all4, loss_val_all4, acc_val_all4 = train_model(model2,epochs,train_dataloader,val_dataloader,\"PointCNN-LR0.01\",learn_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_lines_same_x(y1, y2):\n",
    "    if len(y1) != len(y2):\n",
    "        raise ValueError(\"The lists must have the same length.\")\n",
    "\n",
    "    x = list(range(len(y1)))  # Generates an x-axis based on the length of the y-values lists\n",
    "\n",
    "    plt.plot(x, y1, label='train')\n",
    "    plt.plot(x, y2, label='val')\n",
    "    plt.xlabel('X axis (based on list length)')\n",
    "    plt.ylabel('Y axis')\n",
    "    plt.title('Plot of Two Lines with Shared X Axis')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_two_lines_same_x(acc_train_all1, acc_val_all1)\n",
    "plot_two_lines_same_x(acc_train_all2, acc_val_all2)\n",
    "plot_two_lines_same_x(acc_train_all3, acc_val_all3)\n",
    "plot_two_lines_same_x(acc_train_all4, acc_val_all4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = \"./saved_models/PointNet-LR0.0001/model_10.pth\"\n",
    "model_path2 = \"./saved_models/PointNet-LR0.00001/model_10.pth\"\n",
    "test_path = \"./combined_asl_alphabet/Test_Alphabet\"\n",
    "\n",
    "actuals1, predicteds1, count1, failcount1, wrongs1, errored1 = predict_images(model_path1, test_path, \"./misclassified\")\n",
    "actuals2, predicteds2, count2, failcount2, wrongs2, errored2 = predict_images(model_path2, test_path, \"./misclassified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errored1)\n",
    "accuracy1 = calculate_accuracy(actuals1, predicteds1)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errored2)\n",
    "accuracy2 = calculate_accuracy(actuals2, predicteds2)\n",
    "print(accuracy2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
